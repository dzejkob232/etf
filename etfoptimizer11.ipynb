{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dzejkob232/etf/blob/main/etfoptimizer11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b35e211-e24c-4216-ab55-727b8e0a8980",
      "metadata": {
        "id": "7b35e211-e24c-4216-ab55-727b8e0a8980",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install yfinance\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.optimize import minimize\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ffc4c1d-5625-4fb5-8164-826bfd115f2f",
      "metadata": {
        "id": "0ffc4c1d-5625-4fb5-8164-826bfd115f2f"
      },
      "outputs": [],
      "source": [
        "\n",
        "def calculate_returns(data):\n",
        "    data = data.loc[:, ~data.columns.duplicated()]\n",
        "    returns = data.pct_change(fill_method=None)\n",
        "    returns = returns.dropna(how='all')\n",
        "    return returns\n",
        "\n",
        "def calculate_ewma_statistics(returns, span=1260):\n",
        "    # Check if the DataFrame is empty\n",
        "    if returns.empty:\n",
        "        raise ValueError(\"The returns DataFrame is empty. Please check your data.\")\n",
        "    ewma_mean = returns.ewm(span=span).mean().iloc[-1]\n",
        "    ewma_std = returns.ewm(span=span).std().iloc[-1]\n",
        "    return ewma_mean, ewma_std\n",
        "\n",
        "def calculate_ewma_covariance_matrix(returns, span=1260):\n",
        "    \"\"\"\n",
        "    Calculates the EWMA covariance matrix for all ETFs.\n",
        "    \"\"\"\n",
        "    ewm_cov = returns.ewm(span=span).cov()\n",
        "    # Identify which level of the MultiIndex contains the dates\n",
        "    level0 = ewm_cov.index.get_level_values(0)\n",
        "    level1 = ewm_cov.index.get_level_values(1)\n",
        "    if isinstance(level0[0], pd.Timestamp):\n",
        "        date_level = 0\n",
        "    elif isinstance(level1[0], pd.Timestamp):\n",
        "        date_level = 1\n",
        "    else:\n",
        "        raise ValueError(\"No date level found in ewm_cov index.\")\n",
        "    # Get the last date from the correct index level\n",
        "    last_date = ewm_cov.index.get_level_values(date_level).max()\n",
        "    # Extract the covariance matrix corresponding to the last date\n",
        "    ewma_cov_matrix = ewm_cov.xs(last_date, level=date_level)\n",
        "    return ewma_cov_matrix\n",
        "\n",
        "\n",
        "\n",
        "def calculate_sortino_ratio_ewma(returns, annual_rfr=0.04, span=1260):\n",
        "    daily_rfr = annual_rfr / 252\n",
        "    ewma_mean = returns.ewm(span=span).mean()\n",
        "    ewma_downside_std = returns[returns < daily_rfr].ewm(span=span).std()\n",
        "    expected_returns = ewma_mean.iloc[-1]\n",
        "    downside_std = ewma_downside_std.iloc[-1]\n",
        "    sortino_ratios = (expected_returns - daily_rfr) / downside_std\n",
        "    sortino_ratios = sortino_ratios.replace([np.inf, -np.inf], np.nan).dropna().sort_values(ascending=False)\n",
        "    return sortino_ratios\n",
        "\n",
        "def optimize_portfolio_ewma(returns, selected_etfs, annual_rfr, span=1260):\n",
        "    daily_rfr = annual_rfr / 252\n",
        "    returns_selected = returns[selected_etfs].dropna(how='any')\n",
        "    if returns_selected.empty or len(returns_selected) < 2:\n",
        "        raise ValueError(\"No overlapping data or insufficient data for selected ETFs.\")\n",
        "    ewma_expected_returns = returns_selected.ewm(span=span).mean().iloc[-1]\n",
        "    ewm_cov = returns_selected.ewm(span=span).cov().dropna()\n",
        "    last_date = ewm_cov.index.get_level_values(0).max()\n",
        "    ewma_cov_matrix = ewm_cov.loc[last_date]\n",
        "    ewma_cov_matrix = ewma_cov_matrix.loc[selected_etfs, selected_etfs]\n",
        "    def negative_sharpe_ratio(weights):\n",
        "        portfolio_return = np.dot(weights, ewma_expected_returns)\n",
        "        portfolio_std_dev = np.sqrt(np.dot(weights.T, np.dot(ewma_cov_matrix, weights)))\n",
        "        sharpe_ratio = (portfolio_return - daily_rfr) / portfolio_std_dev\n",
        "        return -sharpe_ratio\n",
        "    n_assets = len(selected_etfs)\n",
        "    initial_guess = np.array([1 / n_assets] * n_assets)\n",
        "    bounds = [(0, 1)] * n_assets\n",
        "    constraints = {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}\n",
        "    result = minimize(\n",
        "        negative_sharpe_ratio,\n",
        "        initial_guess,\n",
        "        method='SLSQP',\n",
        "        bounds=bounds,\n",
        "        constraints=constraints\n",
        "    )\n",
        "    if result.success:\n",
        "        optimized_weights = result.x\n",
        "        portfolio_return = np.dot(optimized_weights, ewma_expected_returns)\n",
        "        portfolio_std_dev = np.sqrt(np.dot(optimized_weights.T, np.dot(ewma_cov_matrix, optimized_weights)))\n",
        "        sharpe_ratio = (portfolio_return - daily_rfr) / portfolio_std_dev\n",
        "        portfolio = pd.DataFrame({'ETF': selected_etfs, 'Weight': optimized_weights})\n",
        "        portfolio['Weight'] = portfolio['Weight'] / portfolio['Weight'].sum()\n",
        "        return portfolio, portfolio_return, portfolio_std_dev, sharpe_ratio\n",
        "    else:\n",
        "        raise ValueError(\"Optimization failed.\")\n",
        "\n",
        "def plot_ios(portfolios, returns, annual_rfr):\n",
        "    daily_rfr = annual_rfr / 252\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    colors = plt.cm.tab10(np.linspace(0, 1, len(portfolios)))\n",
        "    max_sharpe = None\n",
        "    max_sharpe_return = None\n",
        "    max_sharpe_std_dev = None\n",
        "    for idx, portfolio_data in enumerate(portfolios):\n",
        "        portfolio = portfolio_data['Portfolio']\n",
        "        selected_etfs = portfolio['ETF'].tolist()\n",
        "        returns_selected = returns[selected_etfs].dropna(how='any')\n",
        "        if returns_selected.empty or len(returns_selected) < 2:\n",
        "            print(f\"No overlapping data or insufficient data for portfolio {idx+1}. Skipping.\")\n",
        "            continue\n",
        "        expected_returns = returns_selected.mean()\n",
        "        cov_matrix_selected = returns_selected.cov()\n",
        "        num_portfolios = 500\n",
        "        results = np.zeros((num_portfolios, 3))\n",
        "        for i in range(num_portfolios):\n",
        "            weights = np.random.random(len(selected_etfs))\n",
        "            weights /= np.sum(weights)\n",
        "            port_return = np.dot(weights, expected_returns)\n",
        "            port_std_dev = np.sqrt(np.dot(weights.T, np.dot(cov_matrix_selected, weights)))\n",
        "            sharpe_ratio = (port_return - daily_rfr) / port_std_dev\n",
        "            results[i] = [port_std_dev, port_return, sharpe_ratio]\n",
        "            if (max_sharpe is None) or (sharpe_ratio > max_sharpe):\n",
        "                max_sharpe = sharpe_ratio\n",
        "                max_sharpe_return = port_return\n",
        "                max_sharpe_std_dev = port_std_dev\n",
        "        color = colors[idx % len(colors)]\n",
        "        label = '+'.join(selected_etfs)\n",
        "        plt.scatter(results[:, 0], results[:, 1], label=label, color=color, alpha=0.5, s=10)\n",
        "    plt.scatter(0, daily_rfr, color='black', marker='o', label='Risk-Free Asset', s=50)\n",
        "    if max_sharpe is not None:\n",
        "        x_vals = np.linspace(0, max_sharpe_std_dev * 1.5, 100)\n",
        "        cal_line = daily_rfr + max_sharpe * x_vals\n",
        "        plt.plot(x_vals, cal_line, color='red', linestyle='--', label='Capital Allocation Line (CAL)')\n",
        "    plt.title('Investment Opportunity Set (IOS) of Suggested Portfolios')\n",
        "    plt.xlabel('Portfolio Standard Deviation')\n",
        "    plt.ylabel('Portfolio Expected Return')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "def plot_historical_performance(suggested_portfolios, returns):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for idx, portfolio_data in enumerate(suggested_portfolios):\n",
        "        portfolio = portfolio_data['Portfolio']\n",
        "        selected_etfs = portfolio['ETF'].tolist()\n",
        "        weights = portfolio['Weight'].values\n",
        "        returns_selected = returns[selected_etfs].dropna(how='any')\n",
        "        if returns_selected.empty or len(returns_selected) < 2:\n",
        "            print(f\"No overlapping data or insufficient data for portfolio {idx+1}. Skipping.\")\n",
        "            continue\n",
        "        portfolio_returns = returns_selected.mul(weights, axis=1).sum(axis=1)\n",
        "        cumulative_returns = (1 + portfolio_returns).cumprod()\n",
        "        label = '+'.join(selected_etfs)\n",
        "        plt.plot(cumulative_returns.index, cumulative_returns.values, label=label)\n",
        "    plt.title('Historical Performance of Suggested Portfolios')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Cumulative Return')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "def download_etf_data(etf_list, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Downloads adjusted closing price data for a list of ETFs.\n",
        "    Handles cases where yf.download returns a DataFrame or a Series.\n",
        "    \"\"\"\n",
        "    data = pd.DataFrame()\n",
        "    for etf in etf_list:\n",
        "        try:\n",
        "            print(f\"Downloading data for {etf}...\")\n",
        "            etf_data = yf.download(etf, start=start_date, end=end_date)\n",
        "\n",
        "            # Check if 'Adj Close' exists and get it, otherwise get the first column\n",
        "            if 'Adj Close' in etf_data.columns:\n",
        "                etf_data = etf_data['Adj Close']\n",
        "            else:\n",
        "                etf_data = etf_data.iloc[:, 0] # Get the first column\n",
        "\n",
        "            # Rename the Series or DataFrame column\n",
        "            if isinstance(etf_data, pd.Series):\n",
        "                etf_data = etf_data.rename(etf)\n",
        "            elif isinstance(etf_data, pd.DataFrame):\n",
        "                etf_data = etf_data.rename(columns={etf_data.columns[0]: etf})\n",
        "            else:\n",
        "                print(f\"Unexpected data type for {etf}: {type(etf_data)}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            data = pd.concat([data, etf_data], axis=1)\n",
        "            print(f\"Successfully downloaded data for {etf}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to download data for {etf}: {e}\")\n",
        "            if \"No data found\" in str(e):\n",
        "                print(f\"Trying with a suffix for {etf}...\")\n",
        "                try:\n",
        "                    for suffix in ['.L', '.TO', '.DE']:\n",
        "                        etf_with_suffix = etf + suffix\n",
        "                        etf_data = yf.download(etf_with_suffix, start=start_date, end=end_date)\n",
        "                        # (Repeat same renaming and type checking as above)\n",
        "\n",
        "                        if 'Adj Close' in etf_data.columns:\n",
        "                            etf_data = etf_data['Adj Close']\n",
        "                        else:\n",
        "                            etf_data = etf_data.iloc[:, 0]\n",
        "\n",
        "                        if isinstance(etf_data, pd.Series):\n",
        "                            etf_data = etf_data.rename(etf)\n",
        "                        elif isinstance(etf_data, pd.DataFrame):\n",
        "                            etf_data = etf_data.rename(columns={etf_data.columns[0]: etf})\n",
        "                        else:\n",
        "                            print(f\"Unexpected data type for {etf}: {type(etf_data)}. Skipping.\")\n",
        "                            continue\n",
        "\n",
        "                        data = pd.concat([data, etf_data], axis=1)\n",
        "                        print(f\"Successfully downloaded data for {etf} using suffix {suffix}\")\n",
        "                        break\n",
        "                except Exception as e2:\n",
        "                    print(f\"Failed to download data for {etf} with suffixes: {e2}\")\n",
        "            else:\n",
        "                raise e\n",
        "    data = data.loc[:, ~data.columns.duplicated()]\n",
        "    return data"
      ],
      "metadata": {
        "id": "Q5XPIkLDKmfK"
      },
      "id": "Q5XPIkLDKmfK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(str))\n"
      ],
      "metadata": {
        "id": "kZR-62k0NRbw"
      },
      "id": "kZR-62k0NRbw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13a00c76-f5f2-460c-8827-7f24a2c6b345",
      "metadata": {
        "id": "13a00c76-f5f2-460c-8827-7f24a2c6b345",
        "outputId": "0dcd79d3-1052-43f5-be01-907917e4b67c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for IYR...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded data for IYR\n",
            "Downloading data for QQQ...\n",
            "Successfully downloaded data for QQQ\n",
            "Downloading data for SMH...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded data for SMH\n",
            "Downloading data for EWI...\n",
            "Successfully downloaded data for EWI\n",
            "Downloading data for IWB...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded data for IWB\n",
            "Downloading data for AGG...\n",
            "Successfully downloaded data for AGG\n",
            "Downloading data for ICSU.L...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded data for ICSU.L\n",
            "Downloading data for KXI...\n",
            "Successfully downloaded data for KXI\n",
            "Downloading data for IUSG...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded data for IUSG\n",
            "Downloading data for EWP...\n",
            "Successfully downloaded data for EWP\n",
            "Downloading data for EFA...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded data for EFA\n",
            "Downloading data for XSW...\n",
            "Successfully downloaded data for XSW\n",
            "Downloading data for GREK...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded data for GREK\n",
            "Downloading data for IJR...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded data for IJR\n",
            "Downloading data for CSMIB.MI...\n",
            "Successfully downloaded data for CSMIB.MI\n",
            "Downloading data for XLF...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded data for XLF\n",
            "Downloading data for EWY...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded data for EWY\n",
            "Downloading data for HERG.L...\n",
            "Successfully downloaded data for HERG.L\n",
            "Downloading data for USO...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded data for USO\n",
            "Downloading data for XAR...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded data for XAR\n",
            "Downloading data for EWG...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded data for EWG\n",
            "Downloading data for BRND.L...\n",
            "Successfully downloaded data for BRND.L\n",
            "Downloading data for ONEQ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded data for ONEQ\n",
            "Downloading data for VHYL.L...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded data for VHYL.L\n",
            "Downloading data for SCHD...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded data for SCHD\n",
            "Downloading data for GXC...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded data for GXC\n",
            "Downloading data for EWQ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded data for EWQ\n",
            "Downloading data for ITA...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded data for ITA\n",
            "Downloading data for XLP...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded data for XLP\n",
            "Downloading data for EWC...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded data for EWC\n",
            "Downloading data for QTEC...\n",
            "Successfully downloaded data for QTEC\n",
            "Downloading data for IUFS.L...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded data for IUFS.L\n",
            "Downloading data for TUR...\n",
            "Successfully downloaded data for TUR\n",
            "Downloading data for ^N225...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded data for ^N225\n",
            "Downloading data for LTAM.MI...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded data for LTAM.MI\n",
            "Downloading data for VUKG.L...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded data for VUKG.L\n",
            "Downloading data for SPY...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded data for SPY\n",
            "Downloading data for EWN...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded data for EWN\n",
            "Downloading data for XHB...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded data for XHB\n",
            "Downloading data for FXI...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded data for FXI\n",
            "Downloading data for RYH...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded data for RYH\n",
            "Downloading data for SCHA...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded data for SCHA\n",
            "Downloading data for KWEB...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        }
      ],
      "source": [
        "start_date = '2019-01-01'\n",
        "end_date = '2025-02-27'\n",
        "annual_rfr = 0.06\n",
        "span = 800\n",
        "etf_list = ['IYR', 'QQQ', 'SMH', 'EWI', 'IWB', 'AGG', 'ICSU.L', 'KXI', 'IUSG',\n",
        "            'EWP', 'EFA', 'XSW', 'GREK', 'IJR', 'CSMIB.MI', 'XLF', 'EWY', 'HERG.L',\n",
        "            'USO', 'XAR', 'EWG', 'BRND.L', 'ONEQ', 'VHYL.L', 'SCHD', 'GXC',\n",
        "            'EWQ', 'ITA', 'XLP', 'EWC', 'QTEC', 'IUFS.L', 'TUR', '^N225',\n",
        "            'LTAM.MI', 'VUKG.L', 'SPY', 'EWN', 'XHB', 'FXI', 'RYH', 'SCHA', 'KWEB',\n",
        "            'EZA', '^RUT', 'QDVE.DE', 'EWA', 'XLY', 'XSD', 'CEBS.DE', 'XLE', 'GDXJ',\n",
        "            'EGPT', 'FSTA', 'SPY4.DE', 'VWO', 'FUTY', 'VGOV.L', 'SCHB', 'FEUZ.L', 'VGK',\n",
        "            'NUCG.L', '^STOXX50E', 'EEM', 'FMAT', 'IXG', 'SCHE', 'IHI', 'IEMG', 'HEALL.XC',\n",
        "            'WLDS.L', 'XLU', 'EWD', 'IWO', 'IUESX', 'VNM', 'XLI', 'IHF', 'INDA', 'SPLG',\n",
        "            '^IBEX', 'IWN', 'VWRP.L', 'EPHE', 'RCD', 'DFNS.L', 'RXI', 'HEAW.L', 'SCHF',\n",
        "            'EWU', 'FSEM.L', 'EMLC', 'IDX', 'SCHC', 'EWH', 'XLV', 'EWW', 'WIGG.L', 'IWP',\n",
        "            'RHS', 'EQQQ.DE', 'WCOS.AS', 'IWF', 'IEV', 'SCHX', 'XME', 'GDX', 'UNG', 'EIS',\n",
        "            'RSX', 'SGLN.L', 'EWL', 'IWD', 'EWO', 'IWS', 'IVV', 'XLK', 'IXJ', 'SCHG', 'SCHV',\n",
        "            'XLB', 'EWZ', 'IWR', 'EWJ', 'PSJ', 'THD', 'EMB', 'IJH', 'ECH', 'EWT', 'GSEM.L',\n",
        "            'IUSV', 'STW.PA', 'IWM', 'XRT', 'ARGT', 'VEA', 'FIDU', 'PKW', 'EPOL', 'XLRE',\n",
        "            'INRG.MI','CUKX.L','IGUS.L','CPJ1.L','EHYG.L','EEDG.L','EMHG.L','ROLG.L','FXC',\n",
        "            'IGLT.L','UESD.L','SSLN.L','EMGA.L','ECAR.L','TLT5.L','WTRE','STHS.L','GGRG.L',\n",
        "            'NATP.L','TLTE','XSOE','GOAI.SW','GSLC','TKN.TO','FSMG.L','CLMP.L','CMDY','KWEB',\n",
        "            'KLWD.L','WBIO.L','TLT5.L','ARKG','ARKK','ARKW','REUSEM.XC','PSI20.LS','EWQ','^STI','EWA',\n",
        "            'EWZ','^MXY','REUG', '^FCHI','^NQMAMCN','^DJEG20','XIU.TO','^HSI','000001.SS'\n",
        "            '^NSEI','IDX','PSEI.PS','XU100.IS','ATX','^EWN-IV','^OMX','^OMXC25','^OMXH25','ESNB.DE',\n",
        "            '0P0000RRIV.SW','^MERV','VNM','GLD3','TRET.L','HINS.L','HPRO.L','ROLG.L','WCOA','COCO.MI',\n",
        "            'UGAS.MI','KC=F','3HCL.MI','SPDM.L','CYSE.L','WLDS.L','DLTM.L','LILAK','ALAG.L','LGQM.DE','GGAL',\n",
        "            'YPFD.BA','PAM','SPY','IKOR','RARE.MI','REMX','URNM',\n",
        "            'AIR.DE','RHM.DE','LDO.MI','DSY.PA','BA.L','RTX','LMT','HO.PA']\n",
        "data = download_etf_data(etf_list, start_date, end_date)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47b07b5d-d16d-4b8f-92bf-d55ea94eabe8",
      "metadata": {
        "id": "47b07b5d-d16d-4b8f-92bf-d55ea94eabe8"
      },
      "outputs": [],
      "source": [
        "excluded_etfs = ['REUS.L','UESD.L','TLT','REUSEM.XC','HEALL.XC','ARGT','EGPT','GGAL','COCO.MI']  # Replace with ETFs you want to exclude\n",
        "data = data.drop(columns=excluded_etfs, errors='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4e409d4-3378-4aba-bcad-fdfe4c857974",
      "metadata": {
        "scrolled": true,
        "id": "c4e409d4-3378-4aba-bcad-fdfe4c857974"
      },
      "outputs": [],
      "source": [
        "returns = calculate_returns(data)\n",
        "ewma_expected_returns, ewma_std_devs = calculate_ewma_statistics(returns, span=1260)\n",
        "ewma_cov_matrix = calculate_ewma_covariance_matrix(returns, span=1260)\n",
        "sortino_ratios = calculate_sortino_ratio_ewma(returns, annual_rfr, span=1260)\n",
        "print(\"Sortino Ratios (EWMA):\")\n",
        "print(sortino_ratios.head(10))\n",
        "\n",
        "# Selection of ETFs\n",
        "\n",
        "# 9 best Sortino ratios tagged as 'best'\n",
        "best_etfs = sortino_ratios.head(16).index.tolist()\n",
        "etf_tags = {etf: 'best' for etf in best_etfs}\n",
        "\n",
        "# 4 highest expected returns (excluding already selected), tagged as 'earn'\n",
        "remaining_etfs = ewma_expected_returns.drop(index=best_etfs)\n",
        "top_er_etfs = remaining_etfs.sort_values(ascending=False).head(4).index.tolist()\n",
        "for etf in top_er_etfs:\n",
        "    etf_tags[etf] = 'earn'\n",
        "\n",
        "# Combine selected ETFs\n",
        "selected_etfs = best_etfs + top_er_etfs\n",
        "used_etfs = set(selected_etfs)\n",
        "\n",
        "# For each selected ETF, find ETFs according to specified criteria\n",
        "for etf in best_etfs + top_er_etfs:\n",
        "    # Find lowest covariance pair (tagged 'hedge')\n",
        "    remaining = set(returns.columns) - used_etfs\n",
        "    if not remaining:\n",
        "        break\n",
        "    cov_series = ewma_cov_matrix.loc[etf, list(remaining)].dropna()\n",
        "    if cov_series.empty:\n",
        "        continue\n",
        "    hedge_etf = cov_series.idxmin()\n",
        "    selected_etfs.append(hedge_etf)\n",
        "    etf_tags[hedge_etf] = 'hedge'\n",
        "    used_etfs.add(hedge_etf)\n",
        "\n",
        "    # Find lowest covariance ETF with e(r) > risk-free rate (tagged 'mid')\n",
        "    er_filtered = ewma_expected_returns[list(remaining)]\n",
        "    er_filtered = er_filtered[er_filtered > annual_rfr / 252]\n",
        "    if not er_filtered.empty:\n",
        "        cov_series_er = ewma_cov_matrix.loc[etf, er_filtered.index].dropna()\n",
        "        if not cov_series_er.empty:\n",
        "            mid_etf = cov_series_er.idxmin()\n",
        "            selected_etfs.append(mid_etf)\n",
        "            etf_tags[mid_etf] = 'mid'\n",
        "            used_etfs.add(mid_etf)\n",
        "\n",
        "    # Find lowest covariance ETF from top 20% Sortino ratio (tagged 'high')\n",
        "    sortino_top_20 = sortino_ratios.head(int(len(sortino_ratios) * 0.2))\n",
        "    remaining_high = set(sortino_top_20.index) - used_etfs\n",
        "    if remaining_high:\n",
        "        cov_series_high = ewma_cov_matrix.loc[etf, list(remaining_high)].dropna()\n",
        "        if not cov_series_high.empty:\n",
        "            high_etf = cov_series_high.idxmin()\n",
        "            selected_etfs.append(high_etf)\n",
        "            etf_tags[high_etf] = 'high'\n",
        "            used_etfs.add(high_etf)\n",
        "\n",
        "print(\"\\nSelected ETFs and their tags:\")\n",
        "for etf in selected_etfs:\n",
        "    print(f\"{etf}: {etf_tags.get(etf, 'unlabeled')}\")\n",
        "\n",
        "selected_etfs = list(used_etfs)\n",
        "print(\"\\nFinal list of candidate ETFs:\")\n",
        "print(selected_etfs)\n",
        "\n",
        "# Check overlapping data\n",
        "returns_selected = returns[selected_etfs].dropna()\n",
        "if len(returns_selected) < 200:\n",
        "    print(\"\\nInsufficient overlapping data for selected ETFs.\")\n",
        "    # Optionally, implement logic to exclude problematic ETFs and select replacements\n",
        "else:\n",
        "    print(\"\\nSufficient overlapping data for selected ETFs.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e1bf7b6-9a73-4e7c-9b57-fe18d2bff767",
      "metadata": {
        "id": "6e1bf7b6-9a73-4e7c-9b57-fe18d2bff767"
      },
      "outputs": [],
      "source": [
        "# Calculate the number of non-NaN entries for each selected ETF\n",
        "data_coverage = data[selected_etfs].notna().sum().sort_values()\n",
        "\n",
        "print(\"Data Coverage for Each Selected ETF:\")\n",
        "print(data_coverage)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cfef375-391f-4abd-ae4b-2881f1ba94da",
      "metadata": {
        "id": "6cfef375-391f-4abd-ae4b-2881f1ba94da"
      },
      "outputs": [],
      "source": [
        "print(data.isna().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c11bd090-1a0c-4bd8-aa5c-4ab753ddb79e",
      "metadata": {
        "scrolled": true,
        "id": "c11bd090-1a0c-4bd8-aa5c-4ab753ddb79e"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    portfolio, port_return, port_std_dev, sharpe_ratio = optimize_portfolio_ewma(\n",
        "        returns, selected_etfs, annual_rfr, span=1260)\n",
        "    portfolio['Weight'] = portfolio['Weight'].apply(lambda x: round(x, 3))\n",
        "    print(\"\\nOptimized Portfolio:\")\n",
        "    print(portfolio)\n",
        "    print(f\"Expected Return: {port_return:.5f}, Std Dev: {port_std_dev:.5f}, Sharpe Ratio: {sharpe_ratio:.5f}\")\n",
        "    suggested_portfolios = [{\n",
        "        'Portfolio': portfolio,\n",
        "        'Returns': [port_return],\n",
        "        'StdDevs': [port_std_dev],\n",
        "        'SharpeRatio': sharpe_ratio\n",
        "    }]\n",
        "except ValueError as e:\n",
        "    print(f\"Optimization failed: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed9c1d00-a7c0-4857-9d68-f9bf0ec4e24d",
      "metadata": {
        "id": "ed9c1d00-a7c0-4857-9d68-f9bf0ec4e24d"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    portfolio, port_return, port_std_dev, sharpe_ratio = optimize_portfolio_ewma(\n",
        "        returns, selected_etfs, annual_rfr, span=1260)\n",
        "    portfolio['Weight'] = portfolio['Weight'].apply(lambda x: round(x, 3))\n",
        "\n",
        "    # Filter out ETFs with weight approximately 0\n",
        "    filtered_portfolio = portfolio[portfolio['Weight'] > 0]\n",
        "\n",
        "    print(\"\\\\nOptimized Portfolio:\")\n",
        "    print(filtered_portfolio)\n",
        "    print(f\"Expected Return: {port_return:.5f}, Std Dev: {port_std_dev:.5f}, Sharpe Ratio: {sharpe_ratio:.5f}\")\n",
        "    suggested_portfolios = [{\n",
        "        'Portfolio': filtered_portfolio,\n",
        "        'Returns': [port_return],\n",
        "        'StdDevs': [port_std_dev],\n",
        "        'SharpeRatio': sharpe_ratio\n",
        "    }]\n",
        "except ValueError as e:\n",
        "    print(f\"Optimization failed: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b996de8-a39f-47aa-b203-d1a7aa530785",
      "metadata": {
        "id": "6b996de8-a39f-47aa-b203-d1a7aa530785"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66669bea-8bd4-4038-8191-64149bb5ee66",
      "metadata": {
        "id": "66669bea-8bd4-4038-8191-64149bb5ee66"
      },
      "outputs": [],
      "source": [
        "plot_ios(suggested_portfolios, returns, annual_rfr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eddb470e-8b6d-494e-b66c-3bb757d9cae6",
      "metadata": {
        "id": "eddb470e-8b6d-494e-b66c-3bb757d9cae6"
      },
      "outputs": [],
      "source": [
        "plot_historical_performance(suggested_portfolios, returns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "545a656f-a9c0-412e-9620-92f8929a0dde",
      "metadata": {
        "id": "545a656f-a9c0-412e-9620-92f8929a0dde"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c904ebf1-e638-47eb-b381-2b554860ec04",
      "metadata": {
        "id": "c904ebf1-e638-47eb-b381-2b554860ec04"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9950f6ee-ae95-4de9-ad12-94c86a2cf524",
      "metadata": {
        "id": "9950f6ee-ae95-4de9-ad12-94c86a2cf524"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "def expand_portfolio(base_portfolio, returns, min_base_weight=0.5, annual_rfr=0.06, span=1260):\n",
        "    \"\"\"\n",
        "    Composes an optimal portfolio expansion using the base portfolio as a required component.\n",
        "\n",
        "    Args:\n",
        "    - base_portfolio (dict): A dictionary with tickers as keys and weights as values.\n",
        "    - returns (pd.DataFrame): DataFrame containing returns for all available tickers.\n",
        "    - min_base_weight (float): The minimum weight of the base portfolio in the final result (0 < min_base_weight < 1).\n",
        "    - annual_rfr (float): Annual risk-free rate (default is 0.06).\n",
        "    - span (int): Span for the EWMA calculations (default is 1260).\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame: DataFrame with the optimized weights for the expanded portfolio.\n",
        "    - float: Expected return of the expanded portfolio.\n",
        "    - float: Standard deviation of the expanded portfolio.\n",
        "    - float: Sharpe ratio of the expanded portfolio.\n",
        "    \"\"\"\n",
        "    if not (0 < min_base_weight < 1):\n",
        "        raise ValueError(\"min_base_weight must be between 0 and 1.\")\n",
        "\n",
        "    # 1. Check if base portfolio tickers are in returns DataFrame\n",
        "    base_tickers = list(base_portfolio.keys())\n",
        "    missing_base_tickers = [ticker for ticker in base_tickers if ticker not in returns.columns]\n",
        "    if missing_base_tickers:\n",
        "        raise ValueError(f\"The following tickers from the base portfolio are missing in the 'returns' DataFrame: {missing_base_tickers}\")\n",
        "\n",
        "    # 2. Get tickers for expansion (all downloaded tickers not in base portfolio)\n",
        "    all_downloaded_tickers = returns.columns.tolist()\n",
        "    expansion_tickers = [ticker for ticker in all_downloaded_tickers if ticker not in base_tickers]\n",
        "\n",
        "    if not expansion_tickers:\n",
        "        raise ValueError(\"No additional tickers available for expansion (all downloaded tickers are already in the base portfolio).\")\n",
        "\n",
        "    # 3. Prepare data for optimization\n",
        "    base_weights = np.array(list(base_portfolio.values()))\n",
        "    base_weights /= base_weights.sum()  # Normalize base weights\n",
        "\n",
        "    returns_base = returns[base_tickers].dropna(how='any')  # Returns for base portfolio\n",
        "    returns_expansion = returns[expansion_tickers].dropna(how='any') # Returns for expansion tickers\n",
        "\n",
        "    ewma_expected_returns = returns_base.ewm(span=span).mean().iloc[-1] #Expected returns for base portfolio\n",
        "\n",
        "    # Assuming ewma_cov_matrix is calculated for all assets and not just base assets\n",
        "    ewma_cov_matrix = returns[base_tickers + expansion_tickers].ewm(span=span).cov().xs(returns.index[-1], level=0) # Covariance matrix of base and expansion portfolio\n",
        "\n",
        "    # 4. Define optimization function\n",
        "    def negative_sharpe_ratio(weights):\n",
        "        # Combine base and expansion weights\n",
        "        combined_weights = np.hstack((min_base_weight * base_weights, (1 - min_base_weight) * weights))\n",
        "        #Get expected returns of combined portfolio (base + expansion)\n",
        "        portfolio_return = np.dot(combined_weights, ewma_expected_returns.append(returns_expansion.ewm(span=span).mean().iloc[-1]))\n",
        "        #Get std deviation of combined portfolio (base + expansion)\n",
        "        portfolio_std_dev = np.sqrt(np.dot(combined_weights.T, np.dot(ewma_cov_matrix, combined_weights)))\n",
        "        sharpe_ratio = (portfolio_return - (annual_rfr / 252)) / portfolio_std_dev\n",
        "        return -sharpe_ratio\n",
        "\n",
        "    # 5. Perform optimization\n",
        "    initial_guess = np.array([1 / len(expansion_tickers)] * len(expansion_tickers))\n",
        "    bounds = [(0, 1)] * len(expansion_tickers)\n",
        "    constraints = {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}\n",
        "\n",
        "    result = minimize("
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "258c02d8-04fb-4e31-845c-f11d67d7045d",
      "metadata": {
        "id": "258c02d8-04fb-4e31-845c-f11d67d7045d"
      },
      "outputs": [],
      "source": [
        "expand_portfolio({'URNM':0.25,'REMX':0.25,'RARE.MI':0.5})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8979809e-ee34-4b78-ade5-f71909ec1df1",
      "metadata": {
        "id": "8979809e-ee34-4b78-ade5-f71909ec1df1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}